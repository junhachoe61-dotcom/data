# PRD: DataTrust-Light
**금융권용 초경량 데이터 신뢰성 확보 체계**

---

## 1. 프로젝트 개요 (Project Overview)

### 1.1 회사명 및 포지션
- **회사**: 토스뱅크 (Toss Bank)
- **타겟 포지션**: Data Engineering Department Leader
- **프로젝트명**: DataTrust-Light

### 1.2 프로젝트 배경 (Background)
토스뱅크와 같은 금융 환경에서는 데이터 정합성이 비즈니스 의사결정과 규제 준수에 직결됩니다. 그러나 전통적인 데이터 거버넌스 솔루션(Datahub, Amundsen 등)은 다음과 같은 문제점을 가지고 있습니다:

- **높은 초기 구축 비용**: 대규모 인프라 구축과 유지보수에 상당한 엔지니어링 리소스 소모
- **보이지 않는 데이터 사고**: 파이프라인 증가에 따른 상위 소스 변경의 하위 영향도 파악 어려움
- **비효율적인 운영**: 인프라 관리에 리소스가 집중되어 데이터 비즈니스 가치 창출에 집중 불가

### 1.3 프로젝트 목적 (Objectives)
서버리스 및 오픈소스 기반의 **최소 비용**으로 데이터 품질 검증(Quality)과 흐름 추적(Lineage)을 자동화하는 프레임워크를 구축하여:

1. **비용 효율성**: 운영 비용을 기존 대비 90% 이상 절감
2. **데이터 신뢰성**: 품질 검증을 통한 데이터 정합성 99.9% 유지
3. **빠른 장애 대응**: 데이터 사고 인지 시간(MTTD) 80% 이상 단축
4. **확장 가능성**: 표준 기반 설계로 향후 엔터프라이즈 솔루션 마이그레이션 용이

### 1.4 타겟 사용자 (Target Users)
- **데이터 엔지니어**: 파이프라인 개발 및 품질 관리
- **데이터 분석가**: 신뢰할 수 있는 데이터 기반 분석
- **비즈니스 리더**: 데이터 기반 의사결정
- **컴플라이언스 팀**: 규제 대응 및 감사 추적

---

## 2. 핵심 기능 (Key Features)

### 2.1 선제적 품질 가드레일 (Data Quality Guardrail)

#### 기능 설명
데이터 파이프라인의 각 단계에서 자동으로 품질을 검증하여 불량 데이터가 하위로 전파되는 것을 차단합니다.

#### 주요 검증 항목
- **스키마 검증**: 컬럼 타입, 필수 필드 존재 여부
- **데이터 무결성**: Null 값 비율, 중복 데이터 검사
- **비즈니스 규칙**: 값의 범위, 참조 무결성, 도메인 규칙
- **통계적 이상 탐지**: 평균/표준편차 기반 이상치 감지

#### Circuit Breaker 메커니즘
```yaml
# 예시: Soda Core 품질 규칙
checks for transactions:
  - row_count > 0
  - missing_count(user_id) = 0
  - invalid_percent(amount) < 1%
  - freshness(created_at) < 1h
```

품질 기준 미달 시:
1. 하위 파이프라인 실행 자동 중단
2. Slack/Email 알림 발송
3. 메타데이터에 품질 검증 결과 기록

### 2.2 자동화된 데이터 리니지 (Automated Lineage)

#### 기능 설명
데이터의 생성부터 소비까지의 전체 경로를 자동으로 추적하고 시각화합니다.

#### 추적 정보
- **소스 → 변환 → 타겟** 경로 매핑
- **의존성 그래프**: 상위/하위 데이터셋 관계
- **변경 이력**: 스키마 변경, 데이터 변환 로직 변경
- **실행 이력**: 작업 성공/실패, 실행 시간, 데이터 볼륨

#### 활용 시나리오
- **영향도 분석**: 소스 테이블 변경 시 영향받는 모든 하위 리포트 파악
- **감사 대응**: 특정 지표의 데이터 출처 및 변환 과정 추적
- **장애 원인 분석**: 데이터 품질 이슈 발생 시 원인 소스 역추적

### 2.3 운영 비용 최적화 (Cost Efficiency)

#### 서버리스 아키텍처
- **GitHub Actions**: 워크플로우 오케스트레이션 (무료 티어 활용)
- **DuckDB**: 인메모리 분석 엔진 (별도 DB 서버 불필요)
- **S3**: 데이터 레이크 스토리지 (저비용 객체 스토리지)

#### 비용 절감 효과
| 항목 | 기존 솔루션 | DataTrust-Light | 절감률 |
|------|------------|-----------------|--------|
| 인프라 비용 | $5,000/월 | $500/월 | 90% |
| 운영 인력 | 2 FTE | 0.2 FTE | 90% |
| 초기 구축 기간 | 3개월 | 2주 | 85% |

---

## 3. 기술 스택 (Tech Stack)

### 3.1 아키텍처 다이어그램

```
┌─────────────────────────────────────────────────────────────┐
│                     Data Sources                             │
│  (PostgreSQL, S3, API, Kafka, etc.)                         │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│              GitHub Actions Workflow                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ Data Ingestion│→│Quality Check │→│ Lineage Track│      │
│  │               │  │ (Soda Core)  │  │(OpenLineage) │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│                   Storage & Analysis                         │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   S3 Data    │  │   Marquez    │  │   DuckDB     │      │
│  │     Lake     │  │  (Metadata)  │  │   (Query)    │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────┬───────────────────────────────────────────┘
                  │
                  ▼
┌─────────────────────────────────────────────────────────────┐
│                  Visualization & Alerts                      │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │   Marquez    │  │    Slack     │  │   Grafana    │      │
│  │      UI      │  │  Notification│  │  Dashboard   │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 기술 스택 상세

| 레이어 | 기술 | 선정 이유 |
|--------|------|-----------|
| **Orchestration** | GitHub Actions | • 서버리스 실행 환경<br>• 코드와 워크플로우 통합 관리<br>• 무료 티어 제공 |
| **Quality Check** | Soda Core | • YAML 기반 선언적 규칙 정의<br>• 다양한 데이터 소스 지원<br>• 오픈소스 무료 사용 |
| **Lineage** | OpenLineage | • 업계 표준 메타데이터 스펙<br>• 벤더 중립적 확장성<br>• 다양한 도구와 통합 가능 |
| **Metadata Store** | Marquez | • OpenLineage 네이티브 지원<br>• 시각화 UI 제공<br>• 경량 Docker 배포 |
| **Analysis Engine** | DuckDB | • 인메모리 OLAP 엔진<br>• SQL 인터페이스<br>• 별도 서버 불필요 |
| **Storage** | AWS S3 | • 저비용 객체 스토리지<br>• 높은 내구성 (99.999999999%)<br>• Parquet 포맷 지원 |
| **Monitoring** | Grafana + Prometheus | • 오픈소스 모니터링<br>• 풍부한 시각화<br>• 알림 기능 |

---

## 4. 사용자 여정 (User Journey)

### 4.1 데이터 엔지니어 여정

#### Step 1: 품질 규칙 정의
```yaml
# checks/transactions.yml
table: transactions
checks:
  - row_count > 0
  - missing_count(user_id) = 0
  - invalid_percent(amount) < 1%
  - freshness(created_at) < 1h
  - schema:
      - name: user_id
        type: integer
      - name: amount
        type: decimal
```

#### Step 2: 파이프라인 코드 작성
```python
# pipelines/daily_transactions.py
from openlineage.client import OpenLineageClient

def extract_transactions():
    # OpenLineage 이벤트 자동 발행
    with lineage_context("extract_transactions"):
        data = db.query("SELECT * FROM transactions")
        return data
```

#### Step 3: GitHub Actions 워크플로우 등록
```yaml
# .github/workflows/daily_pipeline.yml
name: Daily Transaction Pipeline
on:
  schedule:
    - cron: '0 0 * * *'
jobs:
  run:
    runs-on: ubuntu-latest
    steps:
      - name: Quality Check
        run: soda scan -d production -c checks/
      - name: Run Pipeline
        run: python pipelines/daily_transactions.py
```

### 4.2 데이터 분석가 여정

#### Step 1: 데이터 신뢰도 확인
Marquez UI에서 데이터셋의 품질 검증 이력 확인:
- ✅ 최근 7일 품질 검증 100% 통과
- ⚠️ 3일 전 freshness 경고 (해결됨)

#### Step 2: 데이터 리니지 탐색
특정 리포트의 데이터 출처 추적:
```
Sales Dashboard
  ← aggregated_sales (DuckDB)
    ← cleaned_transactions (S3)
      ← raw_transactions (PostgreSQL)
```

#### Step 3: 안전한 분석 수행
품질이 보장된 데이터로 분석 진행

### 4.3 장애 발생 시나리오

#### 시나리오: 소스 테이블 스키마 변경
1. **변경 발생**: `transactions` 테이블에 `currency` 컬럼 추가
2. **자동 감지**: Soda Core가 스키마 불일치 감지
3. **즉시 차단**: 하위 파이프라인 실행 중단
4. **알림 발송**: Slack으로 엔지니어에게 알림
   ```
   🚨 Quality Check Failed
   Table: transactions
   Issue: Schema mismatch - unexpected column 'currency'
   Impact: 3 downstream pipelines blocked
   Action Required: Update quality checks and pipeline code
   ```
5. **영향도 분석**: Marquez에서 영향받는 3개 하위 파이프라인 확인
6. **수정 및 재실행**: 코드 수정 후 파이프라인 재실행

---

## 5. 성공 지표 (Success Metrics)

### 5.1 정량적 지표

| 지표 | 목표 | 측정 방법 |
|------|------|-----------|
| **데이터 사고 인지 시간 (MTTD)** | 기존 대비 80% 단축 | 품질 검증 실패부터 알림까지 시간 |
| **인프라 운영 비용** | 상용 도구 대비 90% 절감 | 월간 AWS 비용 + 인건비 |
| **데이터 신뢰도** | 품질 검증 통과율 99.9% | 전체 검증 중 통과 비율 |
| **파이프라인 커버리지** | 전체 파이프라인의 80% | 품질 검증이 적용된 파이프라인 비율 |
| **리니지 추적률** | 전체 데이터셋의 90% | 리니지가 기록된 데이터셋 비율 |

### 5.2 정성적 지표

- **엔지니어 생산성**: 데이터 품질 이슈 디버깅 시간 감소
- **비즈니스 신뢰도**: 데이터 기반 의사결정에 대한 신뢰 향상
- **규제 대응**: 감사 요청 시 데이터 추적 시간 단축
- **조직 확장성**: 신규 데이터 소스 추가 시 설정 시간 단축

### 5.3 측정 대시보드

```
┌─────────────────────────────────────────────────────────────┐
│              DataTrust-Light Metrics Dashboard               │
├─────────────────────────────────────────────────────────────┤
│  Quality Checks (Last 7 Days)                               │
│  ████████████████████████████████████████ 99.8% Pass       │
│                                                              │
│  Pipeline Coverage                                           │
│  ████████████████████████████░░░░░░░░░░░ 85%               │
│                                                              │
│  Mean Time to Detect (MTTD)                                 │
│  ⏱️ 2.3 minutes (↓ 87% from baseline)                      │
│                                                              │
│  Monthly Cost                                                │
│  💰 $450 (↓ 92% from commercial solution)                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 6. 구현 로드맵 (Implementation Roadmap)

### Phase 1: MVP (2주)
**목표**: 핵심 품질 검증 및 리니지 추적 기능 구현

- [x] 기술 스택 선정 및 환경 설정
- [ ] Soda Core 품질 검증 파이프라인 구축
  - PostgreSQL 연동
  - 기본 품질 규칙 정의 (Null, Schema, Freshness)
  - Slack 알림 연동
- [ ] OpenLineage + Marquez 설정
  - Marquez 서버 Docker 배포
  - OpenLineage 클라이언트 통합
  - 샘플 파이프라인 리니지 추적
- [ ] GitHub Actions 워크플로우 구성
  - 일일 배치 파이프라인 스케줄링
  - 품질 검증 자동화

**산출물**:
- 1개 샘플 파이프라인 (거래 데이터 처리)
- 5개 품질 규칙
- 기본 리니지 시각화

### Phase 2: 확장 (2주)
**목표**: 다양한 데이터 소스 및 고급 기능 추가

- [ ] 다중 데이터 소스 지원
  - S3 Parquet 파일 품질 검증
  - Kafka 스트림 데이터 모니터링
  - API 데이터 검증
- [ ] 고급 품질 규칙
  - 통계적 이상 탐지
  - 비즈니스 규칙 검증 (금액 범위, 참조 무결성)
  - 데이터 프로파일링
- [ ] DuckDB 분석 환경 구축
  - S3 데이터 직접 쿼리
  - 품질 메트릭 분석 쿼리
- [ ] Circuit Breaker 메커니즘
  - 품질 실패 시 하위 파이프라인 자동 차단
  - 재시도 로직

**산출물**:
- 5개 이상 파이프라인
- 20개 이상 품질 규칙
- 자동 장애 차단 시스템

### Phase 3: 프로덕션 준비 (1주)
**목표**: 모니터링, 문서화, 안정성 강화

- [ ] 모니터링 대시보드
  - Grafana 대시보드 구성
  - 품질 메트릭 시각화
  - 알림 규칙 설정
- [ ] 문서화
  - 사용자 가이드
  - 품질 규칙 작성 가이드
  - 트러블슈팅 가이드
- [ ] 성능 최적화
  - 대용량 데이터 처리 최적화
  - 캐싱 전략
- [ ] 보안 강화
  - 시크릿 관리 (GitHub Secrets)
  - 접근 제어

**산출물**:
- 운영 대시보드
- 완전한 문서
- 프로덕션 레디 시스템

---

## 7. 리스크 및 완화 전략 (Risks & Mitigation)

### 7.1 기술적 리스크

| 리스크 | 영향도 | 완화 전략 |
|--------|--------|-----------|
| **GitHub Actions 실행 시간 제한** | 중 | • 파이프라인을 작은 단위로 분할<br>• 필요시 Self-hosted runner 사용 |
| **Marquez 서버 장애** | 중 | • 메타데이터 백업 자동화<br>• 리니지 추적 실패 시에도 파이프라인 계속 실행 |
| **대용량 데이터 처리 성능** | 중 | • DuckDB 파티셔닝 활용<br>• 샘플링 기반 품질 검증 옵션 제공 |
| **OpenLineage 표준 변경** | 저 | • 안정 버전 사용<br>• 추상화 레이어 구현 |

### 7.2 운영 리스크

| 리스크 | 영향도 | 완화 전략 |
|--------|--------|-----------|
| **품질 규칙 오탐 (False Positive)** | 고 | • 규칙 테스트 환경 제공<br>• 점진적 규칙 적용 (Warning → Error) |
| **알림 피로도** | 중 | • 알림 우선순위 설정<br>• 알림 집계 (5분 단위) |
| **학습 곡선** | 중 | • 상세한 문서 및 예제 제공<br>• 온보딩 워크샵 진행 |

---

## 8. 리더십 포인트 (Leadership Highlights)

이 프로젝트는 Data Engineering Department Leader 포지션에 지원하기 위한 포트폴리오로서, 다음과 같은 리더십 역량을 보여줍니다:

### 8.1 비즈니스 마인드셋 (Business Mindset)

> "리더로서 기술적 욕심보다는 회사의 비용 효율을 우선시했습니다. 관리 포인트가 적은 서버리스 스택을 선택해 운영 공수를 80% 이상 절감했습니다."

**구체적 성과**:
- 상용 솔루션 대비 90% 비용 절감 ($5,000/월 → $500/월)
- 초기 구축 기간 85% 단축 (3개월 → 2주)
- 운영 인력 90% 절감 (2 FTE → 0.2 FTE)

### 8.2 확장성 (Scalability)

> "현재는 초경량이지만, 모든 메타데이터를 OpenLineage 표준으로 설계했습니다. 조직이 커지면 코드 변경 없이 고성능 관리 도구로 즉시 마이그레이션이 가능합니다."

**설계 원칙**:
- **표준 준수**: OpenLineage 표준으로 벤더 종속성 제거
- **모듈화**: 각 컴포넌트 독립적 교체 가능
- **점진적 확장**: 필요에 따라 Datahub, Amundsen 등으로 마이그레이션 가능

### 8.3 리스크 관리 (Risk Management)

> "금융권에서 가장 중요한 것은 정합성입니다. 'Soda Core'를 통해 데이터 회로 차단기(Circuit Breaker) 개념을 도입, 품질 미달 데이터가 비즈니스 지표에 반영되는 것을 원천 차단했습니다."

**리스크 관리 전략**:
- **선제적 품질 검증**: 데이터 유입 시점에 품질 확인
- **자동 장애 차단**: 품질 미달 시 하위 파이프라인 자동 중단
- **완전한 추적성**: 모든 데이터의 출처와 변환 과정 기록
- **빠른 장애 대응**: MTTD 80% 단축으로 비즈니스 영향 최소화

---

## 9. 향후 발전 방향 (Future Enhancements)

### 9.1 단기 (3-6개월)
- **ML 기반 이상 탐지**: 과거 패턴 학습을 통한 자동 이상치 감지
- **자동 품질 규칙 생성**: 데이터 프로파일링 기반 규칙 자동 제안
- **실시간 스트림 품질 검증**: Kafka 스트림 데이터 실시간 모니터링

### 9.2 중기 (6-12개월)
- **데이터 카탈로그 통합**: 메타데이터 검색 및 디스커버리 기능
- **자동 문서화**: 데이터셋 자동 문서 생성
- **영향도 분석 자동화**: 변경 전 영향받는 시스템 자동 분석

### 9.3 장기 (12개월+)
- **엔터프라이즈 솔루션 마이그레이션**: Datahub 등으로 확장
- **AI 기반 데이터 거버넌스**: 자동 분류, 민감정보 탐지
- **멀티 클라우드 지원**: GCP, Azure 등 다양한 클라우드 환경 지원

---

## 10. 결론 (Conclusion)

DataTrust-Light는 금융권의 데이터 신뢰성 요구사항을 충족하면서도, 최소한의 비용과 운영 부담으로 구현 가능한 실용적인 솔루션입니다.

### 핵심 가치
1. **💰 비용 효율성**: 상용 솔루션 대비 90% 비용 절감
2. **⚡ 빠른 구축**: 2주 내 MVP 구현 가능
3. **🔒 데이터 신뢰성**: 99.9% 품질 검증 통과율
4. **📈 확장 가능성**: 표준 기반 설계로 향후 확장 용이
5. **🎯 리더십 증명**: 비즈니스 마인드셋, 확장성, 리스크 관리 역량 시연

이 프로젝트는 토스뱅크 Data Engineering Department Leader 포지션에서 요구하는 **기술적 전문성**, **비즈니스 이해도**, **리더십 역량**을 모두 보여줄 수 있는 포트폴리오입니다.
